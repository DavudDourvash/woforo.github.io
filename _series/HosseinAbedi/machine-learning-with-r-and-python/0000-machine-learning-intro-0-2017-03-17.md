---
permalink: /series/HosseinAbedi/machine-learning-with-r-and-python/machine-learning-intro-0
title: یادگیری ماشین
author: Hossein Abedi
excerpt: معرفی مفاهیم مربوط به یادگیری ماشین به همراه مثال‌هایی در زبان‌های برنامه‌نویسی پایتون و آر
header:
  image: "/assets/images/HosseinAbedi/headers/mendelbrot.jpg"
is_cover: true
---



## مقدمه

یادگیری ماشین یکی از فیلد‌های هوش ‌مصنوعی  است که به دلیل کاربرد فراوان یافته‌های آن در فناوری‌های مختلف به‌وسیله‌ی شرکت‌هایی نظیر گوگل در دهه‌ی اخیر، توجه زیادی را به خود معطوف کرده‌است.
 با استفاده از روش‌های مطرح شده در یادگیری ماشین می‌توان در هر جایی که یک سری داده‌ی ورودی و خروجی داریم، در مورد رابطه‌ی ورودی  و خروجی بحث کنیم. یادگیری ماشین می‌تواند به ما کمک کند تا با استفاده از داشتن یک مجموعه از داده‌ها به نام داده‌‌ی نمونه، در صورت امکان بخشی از رفتار یک جامعه‌ي آماری را مدل کنیم.
 
 
## تعریف یادگیری

به منظور آشنایی با یادگیری ماشین، ما از تعریف این مفهوم شروع می‌کنیم که در ادامه در قالب یک مثال معرفی می‌گردد. این مثال با وجود ساده‌بودن می‌تواند خواننده را با نوع کلی مساله‌هایی که در یادگیری ماشین مطرح می‌شود آشنا کند.
فرض کنید یک مجموعه $$n$$ تایی از داده‌ها (برای سادگی داده‌ها در دو بعد فرض کنید) داریم که به‌ صورت

\begin{align}
\{(x_0,y_0), (x_1,y_1), ..., (x_i,y_i)..., (x_n,y_n)\}
\end{align}

هستند که در اینجا $$x_i$$ و $$y_i$$
به ترتیب معرف ورودی و خروجی  یک تابع مانند $$c$$
می‌باشند، یعنی 
$$y_i=c(x_i)$$.

تابع $$c$$  در اینجا تابع **مفهوم** (concept) خوانده می‌شود. در حالت ایده‌آل ما می‌خواهیم با داشتن مجموعه زوج مرتب‌های داده‌شده، تابع $$c$$ را بیابیم.
یافتن تابع مفهوم کار نسبتا سخت تا محالی به شمار می‌رود و دلیل این امر این است که 
در دنیای واقعی برای یافتن
$$c$$
با دو چالش زیر روبرو هستیم: 
* در اغلب موارد ممکن است، هیچ دانشی  در مورد خواص $$c$$ وجود نداشته باشد.
* ما به زیر مجموعه‌‌ای از جامعه‌ی زوج مرتب‌های 
$$(x_i, y_i)$$
دسترسی داریم و در واقع ممکن است در بسیاری از مواقع جامعه‌ی مورد نظر دارای تعداد نامتناهی عضو باشد و تابع مفهومی که می‌یابیم تقریبی (نسبتا دقیق تا نادقیق) از تابع مفهوم جامعه است.

‍برای روش‌تر شدن دو چالش بالا فرض کنید ما تعداد ۱۰۰ نمونه داریم که به صورت زوج مرتب‌هایی از وروی و خروجی ما هستند. این ۱۰۰ نمونه به‌وسیله‌ی تابع

\begin{align}
f(x) = 20sin(x) + 10
\end{align}

به صورت 

\begin{align}
\{(0,10), (\pi, 10), ..., (k\pi,10)..., (99\pi, 10)\}
\end{align}

تولید شده‌اند.

در حالت کلی ما در مورد رابطه‌ی وروی و خروجی هیچ اطلاعی نداریم و فقط این ورودی‌ها را به همراه خروجی متناظر آن‌ها در اختیار داریم. نداشتن دانش اولیه 
(aprior knowledge) 
و همین‌طور دسترسی به تعداد اندکی داده از دامنه‌ی این تابع، باعث می‌شود که تعداد توابعی که بتوان برای نامزدی عنوان تابع مفهوم معرفی نمود بیش از یک تابع باشند. برای مثال

\begin{align}
&f_0(x) = 25sin(x) + 10 \\
&f_1(x) = 10 \\
&f_2(x) = 5000sin(x) + 10 
\end{align}

که هر کدام از این توابع، مدل خوبی برای معرفی داده‌های نمونه‌ی ما هستند ولی در عمل ممکن است خطای آن‌ها در یافتن خروجی به ازای ورودی جدید بسیار بالا باشد.

با وجود این دو چالش تقریبا یافتن تابع مفهوم غیر ممکن است. برای فائق آمدن به این دو چالش به جای یافتن تابع مفهوم یک تابع دیگر به نام تابع **فرضیه** (hypothesis) را بر مبنای زیرمجموعه‌ای که در دست داریم (که به آن در حالت مجموعه‌ی آموزشی می گویند) به دست می‌آوریم. در این حالت ما به وسیله‌ی دو روش زیر مساله‌ی یادگیری را به مسله‌ای بسیار راحت‌تر تبدیل می‌کنیم: 
* در همان ابتدا یک سری فرض اولیه (bias) نسبت به اینکه ورودی و خروجی چه رابطه‌ای با هم دارند در نظر می‌گیریم، مثلا رابطه‌ی این رو خطی است و یا چند جمله‌ای درجه ۳ است (با این کار یادگیری از یک مفهوم پیچیده‌ به یافتن ضرایب یک معادله‌ي خطی و یا درجه‌ی  سه جمله‌ای تقلیل می‌یابد).
* در واقع ما با دلیلی دسترسی به بخشی از جامعه‌ی آماری به جای یافتن تابع مفهوم، تخمینی از آن را طی یک فرآیند استنتاج آماری میابیم.

در این حالت خواهیم داشت:

\begin{align}
y_i \approx h(x_i)
\end{align}


که همان‌طور که از علامت
$$\approx$$
بر می‌آید ممکن است تقریب ما با خطا همراه باشد.

## انواع توابع فرضیه

 تعداد توابع فرضیه‌ای که برای یافتن رابطه‌ی تقریبی بین ورودی و خروجی وجود دارد در عمل نسبتا بالاست و روزبه‌روز هم تعدادی تابع جدید معرفی می‌شود که در یک کاربرد خاص ممکن است **تقریب نسبتا کم‌خطا‌تری**  از خود نشان دهد.
توابع فرضیه‌ی مختلف ممکن است با‌ هم در موارد مختلفی، متفاوت باشند ولی در کل فرق اصلی بین آن‌ها معمولا در فرضیای است که در مورد رابطه‌ی ورودی و خروجی در نظر می‌گیرند. 
با آنچه در مورد یادگیری و مفهوم آن در یادگیری ماشین بیان شد، تعداد زیادی از انواع توابع فرضه با ویژگی‌های مختلف و بایاس (فرضیات) متفاوت معرفی شده‌اند که در کاربرد‌های مختلف یادگیری ماشین مورد استفاده قرار‌می گیرند. تعدادی از این توابع فرضیه در قالب روش‌هایی نظیر ماشین بردار پشتیبان (Support Vector Machines)
، انواع شبکه‌های عصبی، رگسیون خطی و چندجمله‌ای بیان می‌شوند که هر کدام فرضیات اولیه‌ی خود را دربر می‌گیرند.




